%! TEX root = ../note-emp-proc-rates.tex

\section{Introduction}

Let \(n \in \mathbb{N}\), \((\Omega, \mathscr{A}, \Pr)\) be an underlying
probability space and \((\mathcal{X}, \mathscr{X})\) be a measurable space.
Let \(Q\) be a signed measure on \((\mathcal{X}, \mathscr{X})\),
and define
\begin{equation*}
  \begin{split}
  Q g :=
  & \, \int g (x) Q (\mathrm{d} x) \quad \text{if } g \in \mathscr{L}_{1} (Q),
  \\
  \text{and} \quad \|Q\|_{\mathcal{F}} :=
  & \, \sup_{f \in \mathcal{F}} |Q f| \quad \text{if} \quad \mathcal{F} \subseteq
  \mathscr{L}_{1} (Q).
  \end{split}
  % \label{eqn--integral-functional-and-norm}
\end{equation*}
Let \(X_{1}, \dots, X_{n}\) be independent \(\mathcal{X}\)-valued random
elements defined on \((\Omega, \mathscr{A}, \Pr)\) and denote the \(\Pr\)-law of
\(X_{i}\) by \(P_{i}\).
Define the measures:
\begin{equation*}
  \begin{gathered}
    \mathbb{P} (A) \equiv \mathbb{P}_{n} (A) := \frac{1}{n} \sum_{i = 1}^{n}
    \delta_{\left\{ X_{i} \right\}} (A) = \frac{1}{n} \sum_{i = 1}^{n}
    \mathbf{1} \left\{ X_{i} \in A \right\} \\
    \text{and} \quad \overline{P} (A) \equiv \overline{P}_{n} (A) := \frac{1}{n}
    \sum_{i = 1}^{n} P_{i} (A).
  \end{gathered}
  % \label{eqn--emp-and-avg-prob-meas}
\end{equation*}
For \(\mathcal{F} \subseteq \mathscr{L}_{1} (\overline{P})\),
the empirical process is the map
\(f \mapsto \left( \mathbb{P} - \overline{P} \right) [f] := \frac{1}{n} \sum_{i
= 1}^{n} \left( f \left( X_{i} \right) - P_{i} f \right)\).

Our main goal here is to provide upper bounds for the tail outer probability
\(\Pr^{\ast} \left\{ \left\| \mathbb{P} - \overline{P} \right\|_{\mathcal{F}} >
y \right\}\) as a function of \(y\), \(n\) and \(\mathcal{F}\).
Dependence on \(\mathcal{F}\) can appear in two ways.
The probability bounds can depend on the supremum second moment of
\(\mathcal{F}\):
\begin{equation*}
  \kappa_{2} (Q, \mathcal{F}) := \sup_{f \in \mathcal{F}} \sqrt{Q \left[
  f^{2} \right]} \quad \text{for a positive measure } Q.
  % \label{eqn--F-2nd-moment-max}
\end{equation*}
Furthermore, the bounds will depend on the complexity of \(\mathcal{F}\); as
in the rest of the empirical process literature, we use covering numbers under
\(\mathscr{L}_{p}\) norms, see \Cref{def--Lr-covering-number} below.
Throughout, we will consider the case where functions in \(\mathcal{F}\) are
uniformly bounded in magnitude by \(1\).

\begin{definition}[\(\mathscr{L}_{p} (Q)\)-covering numbers]
\label{def--Lr-covering-number}
Let \(Q\) be a positive measure on \((\mathcal{X}, \mathscr{X})\) and denote
\begin{equation*}
  \begin{split}
    \|f\|_{p, Q} =
    & \, \begin{cases}
      \left( Q \left[ |f|^{p} \right] \right)^{\frac{1}{p}}
      & \text{if } 1 \leq
      p < \infty, \\
      \inf \{t > 0 : |f| \leq t \ Q\text{-a.e.}\}
      & \text{if } p = \infty,
    \end{cases} \\
    \mathscr{L}_{p} (Q) =
    & \, \left\{ f \text{ measurable such that }  \|f\|_{p, Q} < \infty
    \right\}.
  \end{split}
\end{equation*}
For \(\mathcal{F} \subseteq \mathscr{L}_{p} (Q)\) and \(\varepsilon > 0\),
define
\begin{equation*}
  N \left( \varepsilon, \mathscr{L}_{p} (Q), \mathcal{F} \right) := \min \left\{
  k \in \mathbb{N} : \exists f_{1}, \dots, f_{k} \in \mathcal{F} \text{ s.t. }
  \min_{1 \leq j \leq k} \left( Q \left[ \left| f - f_{j} \right|^{p} \right]
  \right)^{\frac{1}{p}} < \varepsilon \ \forall f \in \mathcal{F} \right\}.
\end{equation*}
\end{definition}

Upon characterizing \(\Pr^{\ast} \left\{ \| \mathbb{P} - \overline{P}
\|_{\mathcal{F}} > y \right\}\), a second goal is then to explore how these
probability bounds can then be used to derive rates of convergence.
A tertiary aim will be to characterize how and when the chaining method offers
an improvement over more crude methods using only covering
numbers, for both probability inequalities and convergence rate results.

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../note-emp-proc-rates"
%%% End:
